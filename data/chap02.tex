% !TeX root = ../thuthesis-example.tex

\chapter{相关工作综述}

\section{引言}

本章对网络流量异常检测领域的相关工作进行了综述。首先介绍了网络流量异常的定义和分类，
异常检测系统的通用框架如图~\ref{fig:scheme}所示。

% 其基础是建立一个代表正常/预期网络行为的基线轮廓，并将任何观察到的与该轮廓相比的当前活动的偏差视为异常。这个基线主要通过统计和历史网络流量数据生成。


% 异常检测是一个重要的领域，自1980年以来，国内外已经有无数学者在这方面做研究。\citet{ahmed2016survey}将异常检测技术分为分类、统计、信息理论和聚类四类。
% 待补充。



\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{异常检测技术的通用架构.png}
    \caption{异常检测的通用框架}
    \label{fig:scheme}
  \end{figure}

% 本章还讨论了用于网络入侵检测的数据集的研究挑战。



\section{网络流量异常的定义和分类}
% hawkins(1980)就此我们给出了异常的一个具有本质性的处理定义[3]:异常就是在一个随机数据集中只能表现被认为不具有所属性差异的那些随机数据，使得有人甚至可以由此怀疑这些差异数据实际上本身并非并没有任何随机的处理偏差，而是产生于一种完全不同的处理机制。
Hawkins(1980)\cite{hawkins1980identification}为“异常”下了一个定义:他指出某些数据由于在数据集中表现出差异，因此值得怀疑这些数据不是一般的随机偏差，而是来自完全不同的机制，我们称这些数据为“异常”。例如在道路交通领域，某条道路的车流量突然增多，甚至多至堵塞，又或者突然减少，此时车流量数据就是一个异常。因此网络行为的异常就是指那些与正常的、标准的，我们所预期的行为相异的表现。为了检测网络异常，网络所有者必须有一个预期或正常行为的概念，我们称其为“基线”。要检测网络行为的异常，就需要确保基线持续稳定，如果我们在监测的过程中发现有不寻常的走向，或者有特殊事件出现，就会合理怀疑有外部的蓄意攻击导致网络流量呈现异常，以及监控指标被改变的状况。

% Hawkins(1980)给出了异常的本质性定义\cite{hawkins1980identification}：异常是在数据集中表现出差异的那些数据，使人怀疑这些数据并非随机偏差，而是产生于完全不同的机制。例如在道路交通领域，某条道路的车流量突然增多，甚至多至堵塞，又或者突然减少，此时车流量数据就是一个异常。因此网络行为的异常就是指那些与正常的、标准的，我们所预期的行为相异的表现。为了检测网络异常，网络所有者必须有一个预期或正常行为的概念，我们称其为基线。要检测网络行为的异常，就需要持续监控网络中的意外趋势或事件，那些可能改变网络流量特征或者监控指标的恶意行为。


限于篇幅，本文只关注引起网络流量特征变化的恶意行为，而对于系统权限提升，缓冲区溢出等黑客攻击手段暂时不做研究。


网络流量异常具体有哪些类别，学术界没有统一的意见。本文中关注的网络流量异常按照产生意图分为恶意和非恶意两类，其中恶意行为主要有拒绝服务攻击、网络扫描、BGP劫持、网络蠕虫、僵尸网络等；非恶意行为主要有物理故障、突发事件等。接下来我们对这些异常分别进行介绍：

\begin{itemize}
  \item 拒绝服务攻击（Denial of Service，DoS）：攻击者往往通过构造大量请求访问目标主机，使其无法处理正常的流量请求，导致正常用户被拒绝服务。
  \item 网络扫描：攻击者在发动网络攻击之前，普遍会先进行网络扫描，否则，黑客可能会向未启动的主机发送恶意报文，从而增加攻击的成本。所以他们总是要先在某个子网范围内扫描出活跃的主机以及可访问的端口。为了以最低代价寻找到可攻击的目标，网络扫描通常是网络攻击的前奏。
  \item BGP劫持：BGP劫持是指通过一个自治系统错误宣称IP为其所有，使得使用边界网关协议维护的互联网路由表的路由器错误地将用户发送的数据传送给非数据传送目的地。BGP劫持很像是攻击者修改了道路路口的路标，使得经过的车辆驶向错误的出口。
  \item 网络蠕虫：网络蠕虫通过网络和电子邮件进行复制和传播，它们首先搜索并且识别出本身具有缺陷的通信端点，在对这些端点施加攻击后,又经由局部地区的私有网路或者庞大的互联网扩散到其他通信端点。例如“熊猫烧香”及其变种就是蠕虫病毒。
  \item 僵尸网络：僵尸网络指由感染了恶意软件的计算机组成的网络，这些计算机集群由攻击者控制。
  \item 物理故障：物理故障也就是指现实世界中的设备有了损坏,包括但不限于电源与设备未连通、路由器无法传输讯息、链路间无法连接、线缆破损等意外事故。
  \item  突发事件：突发事件是指引起网络瞬时拥塞的事件，有可能是管理员配置错误，也有可能是正常的网络操作，如某网站访问量激增。
\end{itemize}

\section{网络流量异常检测算法}


本节将介绍在异常检测领域主流的一些算法，根据所依赖的技术原理的不同，将这些算法分为了基于分类、基于统计、基于聚类、基于信息论的异常检测算法。

\subsection{基于分类的异常检测算法}

% 基于分类的技术依赖于专家对网络攻击特征的广泛了解。当网络专家向检测系统提供详细的特征时，具有已知模式的攻击一经发起就能被检测出来。这完全依赖于攻击的签名，作为一个系统，只有当网络专家较早地提供了攻击的签名，它才能够检测出攻击。这说明一个只能够检测到它所知道的系统很容易受到新的攻击，而新的攻击会不断出现不同的版本，并且更加隐蔽地发起。即使创建了新的攻击的签名并将其纳入系统中，最初的损失也是不可替代的，而且修复程序非常昂贵。


% 基于分类的方法依赖于建立知识库的正常流量活动特征，并将偏离基线特征的活动视为异常活动。这种方法的优势在于它们能够检测到完全新颖的攻击，
% 假设这些攻击表现出大量的偏离正常基线的情况。需要注意的是，由于知识库中未包含的正常流量被认为是攻击，因此会产生无意中的误报。为了避免这种情况，异常检测技术需要进行训练，以建立正常的活动基线，这个建立基线的过程通常非常耗时，而且还取决于是否有完全正常的流量数据集。在实践中，获得无攻击的流量实例是非常罕见且昂贵的。此外，在如今信息更新变换快速的动态网络环境中，保持正常基线的更新是非常困难的。
本文在现有的大量基于分类的网络异常检测技术中，主要讨论以下三种技术，“支持向量机”（Support Vector Machine，SVM），“贝叶斯”（Bayes）以及“神经网络”（Neural Network， NN）。

\subsubsection{SVM}
Eskin等人\cite{2002AEskin} 引入无监督SVM的概念来检测异常事件。常规的SVM的原理是推导出一个超平面，使得正类样本和负类样本之间的分离余量最大化，将特征空间中的两类数据进行分离。标准的SVM算法是一种监督学习方法，需要标记数据来创建分类规则。而该算法经过改进SVM，试图将整个训练数据集从原点分离出来，找到一个以最大余量将数据实例与原点分离的超平面。

Hu等人\cite{Hu2003Robust} 提出了一种忽略噪声数据的异常检测方法，该方法使用Robust SVM(RSVM)来开发。标准的SVM有一个主要假设，即所有的训练样本数据都是独立且相同分布的(i.i.d)。但是在实际场景中，训练数据往往包含噪声，这就会导致标准SVM会学习出一个高度非线性的决策边界，从而导致通用性较差。有鉴于此，RSVM以类中心的形式加入了平均化技术，使得决策面更加平滑。此外，RSVM另一个优点是能大大降低支持向量的数量，从而减少运行时间，提高效率。

% Taeshik Shon等人\cite{shon2005machine} 提出了一种基于增强支持向量机(Enhanced Support Vector Machines)的异常检测算法。增强支持向量机是该文作者提出的一种新型的支持向量机，该向量机同时具备了传统支持向量机的高性能和单类支持向量机检测新异常的能力。在预处理阶段，检测算法使用数据包过滤器滤除畸形数据包。随后，检测算法使用遗传算法对数据包头的信息进行特征选择。接下来，检测算法利用SOM网络对正常流量进行聚类，并用这些聚类来训练增强支持向量机，从而得到最终的异常检测器。

Taeshik Shon 等人\cite{shon2005machine}设计了一种此前未有的增强支持向量机(Enhanced Support Vector Machines)，这种支持向量机的工作能力结合了以往传统支持向量机与单类支持向量机二者已有的优点，不仅性能优良而且也能较好的识别出新出现的异常。增强支持向量机的训练过程也需要经过预处理的几个步骤，首先是用数据包过滤器排查且删除异常数据包。接着是对数据包头进行处理，这个阶段利用到的是遗传算法进行特征选择。在剔除多余无用的特征，且使用SOM网络针对正常流量进行聚类之后，会生成样本集合。用这些样本集合训练增强支持向量机，最后产生出我们所需的异常检测器。


\subsubsection{贝叶斯}

朴素贝叶斯是一个简单的概率分类器，通常用于网络入侵检测问题。 它将先验信息与样本信息结合起来，并以统计推论的方式进行实施，从而利用概率显示出各种形式的不确定性。 朴素贝叶斯假设了所有输入属性在条件上都是彼此独立的。

Kruegel等人\cite{kruegel2003bayesian} 假设异常检测系统包含许多模型，用于分析一个事件的不同特征。他们指出了在这种系统下异常检测技术造成高误报率的两个主要原因：一是异常检测系统通过将多个概率模型的输出进行汇总，而每个模型往往只给出一个事件的常态/异常的得分或概率，从而导致高误报率；二是异常检测系统无法处理那些不正常但合法的行为，如CPU利用率、内存使用率突然增高等。基于贝叶斯网络的概念，Kruegel\citep{kruegel2003bayesian}指出可以使用一种方法降低误报率，该方法能够正确处理那些在合法范围内稍显不正常的行为。对于一个输入事件的有序流($\symbf{S}=e_1,e_2,e_3...$)，异常检测系统决策每个事件是正常还是异常。该决策基于k个模型($\symbf{M}=m_1,m_2,...,m_k$)的输出($o_i|i=1,2,...,k$)和可能的附加信息($\symbf{I}$)。应用贝叶斯网络来识别异常事件，引入根节点，根节点代表一个具有两种状态的变量。一个子节点用于捕捉模型的输出，子节点与根节点相连，预计当输入异常或正常时，输出事件会有所不同。

\subsubsection{神经网络}

神经网络是深度学习的热门技术，早已在多个方面实践成功，但其对计算量的要求很高。神经网络对数据进行分类的优势也可被用于网络异常检测。在网络异常检测领域，神经网络通常会和其他技术进行结合，如统计方法。


Hawkins等人\cite{hawk2002Outlier}提出了一个多层的前馈神经网络，该神经网络可以用来进行异常值的检测。这个多层前馈的神经网络(multi-layer feed-forward neural networks)也就是Replicator Neural Networks。具体而言，它的运行方式是设置了三个隐藏层，夹在输入层和输出层的中间，目标是通过训练，使输出层能以最小的误差重现出输入的数据模式。其原理在于输入层与输出层节点的数量比隐藏层节点的数量要多，因此隐藏层能够具有压缩数据和恢复数据的作用。Replicator Neural Networks的示意图如图~\ref{fig:rnn}所示。

% Hawkins等人\cite{hawk2002Outlier} 提出了一个多层的前馈神经网络，该神经网络可以用来进行异常值的检测。具体来说，Replicator Neural Networks是一个多层前馈的神经网络 (multi-layer feed-forward neural networks)，在输入层和输出层之间放置了三个隐藏层，它的目标是通过训练在输出层以最小的误差重现出输入的数据模式。由于该模型中间隐藏层节点的个数少于输入输出层节点的个数，这样就起到了压缩数据和恢复数据的作用。
% Replicator Neural Networks的示意图如图~\ref{fig:rnn}所示。

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{RNN.jpg}
    \caption{Replicator Neural Networks示意图}
    \label{fig:rnn}
  \end{figure}

  \citet{2001HIDE} 提出了一种分层入侵检测模式，这是他在神经网络的技术基础上搭配了统计方法建立的模型，此系统用一个连续变量($t$)表示神经网络分类器的输出，若变量为1那么当前没有攻击，而-1出现时则是确切的入侵。
  
  除了统计模型，自组织映射(Self-Organizing Map，SOM)亦被用于网络异常检测。Ramadas等人\cite{2003Detecting}提出，由于SOM建基于一个假设：即网络攻击可以由不同的神经元组来描述，这些神经元组与其他神经元组相比，在输出神经元图上覆盖更大的区域。因此利用SOM，可以对网络流量进行实时分类。
  
  Poojitha等人\cite{Poojitha2010} 设计出了一种前馈神经网络，使用的训练算法是“反向传播算法”，该模型的要点在于学习出系统无异常期间所表现出的活动模式，并且将违反此期间的行为归类于异常。

\subsection{基于统计的异常检测算法}
从前检测异常是使用假设-检验的方法，也就是要利用统计与概率模型。第一步是预测数据的分布，并从中找到预先认定的“异常”，在此操作下总是使用极值分析或假设检验。也就是说，当前存在基础的一维数据时，首先拟定数据是遵守正态分布的，若有超出均值达到某个范围外的点，就认定是异常点。此操作推广到高维后，假设各个维度相互独立。这类方法的好处是速度一般比较快，但因总要进行“假设”，所以效果不一定很好。因此统计技术的主要挑战是减少硬阈值引起的误报\cite{cormode2010algorithms}。例如，可以使用统计信号处理程序来提高检测率，同时减少误报，如Lakhina等人在主成分分析工作中所做的工作\cite{lakhina2004diagnosing,lakhina2004structural,lakhina2005mining}。

% 早期的异常检测方法往往基于统计与概率模型，也就是假设-检验的方法。首先对数据的分布做出假设，然后找出假设下所定义的“异常”，因此往往使用极值分析或假设检验。比如对最简单的一维数据假设服从正态分布，然后将距离均值某个范围以外的点当做异常点。推广到高维后，假设各个维度相互独立。这类方法的好处速度一般比较快，但是因为存在很强的“假设”，效果不一定很好。因此统计技术的主要挑战是找到减少硬阈值引起的误报产生的方法\cite{cormode2010algorithms}。例如，可以使用统计信号处理程序来提高检测率，同时减少误报，如Lakhina等人在主成分分析工作中所做的工作\cite{lakhina2004diagnosing，lakhina2004structural，lakhina2005mining}。

Nong等人\cite{Nong2010An}基于卡方检验的距离测量方法，将卡方检验的理论应用于异常检测。根据此技术，首先需要建立一个正常事件的基线，然后将偏离统计值的点视为异常。基于chi-square检验统计量的距离测量方法为：
\begin{equation}
    \chi^2 = \sum_{i=1}^n \frac{(X_i - E_i)^2}{E_i}
\end{equation}
其中$X_i$表示的是第$i$个变量的观测值，$E_i$表示的是第$i$个变量的期望值，变量的数量以$n$表示。当一个变量的观测值接近预期时，$\chi^2$的值就会很低。根据$3\sigma$定律，当观测值的$\chi^2$大于$\bar{X^2}+3S_X^2$时，该值被视为异常。

\subsubsection{小波分析} 
小波变换的基本原理涵盖在傅里叶变换的过程当中，起初三角函数基是无限长的，通过小波变换将其变成长度有限且会衰减的小波基。强大的基函数小波，在时间和频率上是局部的，允许被表示的序列和它们的系数之间有密切的联系。如此一来频率得以获取，同时还可以定位到时间。
% 小波分析的重点是对非稳定数据序列进行建模，这种数据序列可能包含在长时间内振幅和频率都会变化的信号。小波变换的基本原理是在傅里叶变换的过程中，将基由无限长的三角函数基换成有限长的会衰减的小波基。小波是强大的基函数，在时间和频率上是局部的，允许被表示的序列和它们的系数之间有密切的联系。这样不仅能够获取频率，还可以定位到时间。


Callegari等人\cite{callegari2011combining}提出了一种利用小波与基线相结合的实时异常检测方法。它是通过提取NetFlow轨迹，并将其转化为ASCII数据文件，进行路由器级别的分析。经过格式化后，通过哈希函数将不同的流量汇总到基线中。然后，将时间序列数据进行小波变换，若发现不连续点则视为异常点。

另一项使用小波的研究是由Hamdi等人\cite{hamdi2007detecting}产生的。它依赖于通过区分危险和非威胁性的异常来识别与攻击相关的异常。这项任务是在周期观测概念的基础上完成的，小波理论被用来分解一维信号，以分析其特殊频率和时间定位。

\subsubsection{主成分分析}
通常情况下，“主成分分析”(Principal component analysis，PCA)方法的用法是将原本在高维空间里面的数据点,以投影法降至低维空间内。但是我们也可以将之用于检测网络流量异常这个领域。该方法的主要原理是将特征空间为$n$的原数据集映射到新的更小的特征空间$k$中，新特征即为主成分(PC)，其中$k<<n$，这些 PC是一组正交向量，它们构成了一个$k$维子空间。同理，异常点的判别方法，是将存在于初始空间内的那些数据， 映射到主成分空间，接着再把投影拉回到原始的空间。假如进行投影和重构的数据只包含第一主成分，那么大多数的数据在重构前后误差值不大；但是对于异常点而言，重构之后的误差，相较此前的误差值依然很大。

% 主成分分析(Principal component analysis， PCA)是一种常见的降维方法，也可以用于网络流量异常检测领域。该方法的主要原理是将特征空间为$n$的原数据集映射到新的更小的特征空间$k$中，新特征即为主成分(PC)，其中$k<<n$，这些PC是一组正交向量，它们构成了一个$k$维子空间。为了发现异常点，基于主成分分析（PCA）的算法会把原始数据从原始的空间投影到主成分空间，然后再把投影拉回到原始的空间。如果只使用第一主成分来进行投影和重构，对于大多数的数据而言，重构之后的误差是小的；但是对于异常点而言，重构之后的误差依然相对大。

Lakhina等人\cite{lakhina2004diagnosing} 利用主成分分析法将测量结果区分为正常和异常两个子空间，能有效地处理流量异常的判定困难。这个方法是基于将一组网络流量测量所占的高维空间分离成不相干的子空间，两个子空间分别对应正常和异常的网络条件。使用主成分分析法得到的是$k$个子空间，这是与符合一般规律的网络流量行为相应的；至于剩余的$m$ 个子空间($m=n-k$)，则是与异常和噪声对应。接着再把每一个新的流量测量值投射到这$k$和$m$两种子空间上。这样就可以通过区别开相异的阈值,使得测量出的异常值被从正常测量值中划分开来。

利用PCA将流量测量结果有效地分离为正常和异常子空间，解决了网络流量的异常诊断问题。该方法是基于将一组网络流量测量所占的高维空间分离成不相干的子空间，分别对应正常和异常的网络条件。PCA的结果是$k$个子空间，对应正常的网络流量行为，而剩余的$m$个子空间($m=n-k$)则由异常和噪声组成。然后，将每一个新的流量测量值映射到这两个子空间上，这样就可以通过设置不同的阈值将这些测量值划分为正常或异常。

Pascoal等人\cite{pascoal2012robust}提出的异常检测方法采用了鲁棒PCA检测器与鲁棒特征选择算法合并，以获得对不同网络背景和环境的适应性。该鲁棒PCA与经典的PCA方法相反，它对异常值不敏感，并且无需使用可靠标记的数据集进行训练。

Fernandes等人\cite{fernandes2016network}提出了一种基于统计程序主成分分析的异常检测算法。该算法首先生成一个“使用流量分析的网络段数字签名(DSNSF)”的网络基线，然后将该基线与真实网络流量进行比较以识别异常事件。该系统分析了几天内的历史网络流量数据，从中找出最重要的流量时间间隔，同时对数据集进行了缩减，使新的缩减集能够有效地描述正常的网络行为。然后，以DSNSF作为阈值，通过得到的PCA参数，限制一个区间，偏离阈值的被认为是异常的。该系统共使用七个流量特征，三个IP流量特征(bits/s， packets/s， flows/s)被用来生成DSNSF，四个流量属性（源IP地址、目的IP地址、源TCP/UDP端口和目的TCP/UDP端口）被用来生成一个包含有关异常流量间隔的报告。这种方法的缺点是只使用流量属性进行异常检测，只考虑检测基于流量的攻击。


\subsubsection{协方差矩阵}

协方差矩阵是二阶统计，已经被证明是一种强大的异常检测方法。该领域的一个有趣的方向是寻找哪些变量最能标记网络异常，用以提高检测性能。

Yeung等人\cite{yeung2007covariance}采用协方差矩阵分析来检测洪泛攻击。该方法将网络流量建模为协方差矩阵样本，以利用时序样本中包含的统计量达到检测泛洪攻击的目的，直接利用协方差矩阵的变化和相关特征的差异来揭示正常流量与各种类型的洪泛攻击之间的变化。


 Miao Xie等人\cite{xie2014segment}研究了一种基于段的方式处理数据的技术。因为在无线传感器网络(WSNs)中，人们观察到大多数异常事件都会持续相当长的时间。由于现有的异常检测技术通常是以基于点的方式单独处理每个观测值，它们无法可靠和有效地报告在单个传感器节点中出现的这种长期异常。因此该方法采用斯皮尔曼等级相关系数（Spearman's rank correlation coefficient 或 Spearman's $\rho$）和差分压缩概念近似的样本协方差矩阵，以大幅降低计算和通信成本。







% \citet{Christopher2002Service} 提出了一种用于检测异常网络流量的统计处理单元，更具体地说，是为了检测R2L和U2R等罕见的攻击。开发了一种度量方法，使系统能够自动搜索不同服务请求的相同特征。根据以下三个主要特征计算出请求的异常得分。
% 请求的类型；
% 请求的长度；以及
% 有效载荷分布。
% 网络管理员定义了一个阈值，以便对异常请求发出警报。异常得分的计算方法如式(5)，其中有效负载分布的权重大于其他属性。(5)
% 基于统计学理论的原理，我们开发了不同类型的技术来检测异常，接下来将讨论。

% 在时间序列异常检测领域，最常见的基于统计的算法为ARIMA，即差分自回归移动平均模型[8]。我们将流量信号分解为两部分，一是遵循一定规律、可预测的正常变化，二是由突发性变化组成、不可预测的异常情况。ARIMA分析和建模用于网络流量预测，能够检测和识别流量异常或异常值。


\subsection{基于信息论的异常检测算法}

信息论是一门以信息量化和冗余分析为核心的数学学科，其前身是1948年Claude E. Shannon在寻求信号处理和通信操作的数据压缩、传输和存储时提出的设想\cite{shannon1948mathematical}。然而，它的应用扩展到许多其他领域，如电子通信、决策支持系统、模式识别等。常用的信息理论测量方法有香农熵、广义熵、条件熵、相对熵、信息增益和信息成本等。信息论应用于异常检测的途径主要是依靠计算流量特征的相互信息或熵值来识别异常分布。

\subsubsection{熵}
% 熵（entropy）是接收的每条消息中包含的信息的平均量，可以理解为不确定性的度量，因为越随机的信源的熵越大。
熵(entropy)在实验中可以当作是不确定性的度量， 因为它是根据收到的每条消息中所包含的信息，平均后得出的量值，所以信息来源越随机，熵的值就越大。
异常检测领域中，熵可以有效地将流量特征描述为分布，例如源/目的端口或IP地址，因为有某些类型的异常会对严重影响这些分布。通过这种方式，可以检测到例如由目的端口熵的变化表示的端口扫描攻击。

Behal等人\cite{behal2017detection}指出，由于DDoS攻击和突发事件会引起网络流量模式的大幅改变，而基于信息理论的熵或散度可以快速捕捉网络流量行为中的这种差异。因此，他们提出了一种利用流量之间的熵差进行异常检测的算法。通过采用了一组泛化的$\phi$-熵和$\phi$-散度，检测合法流量和攻击流量之间的信息距离。经过实验，该算法对于突发事件和DDoS的检测精度较高，而在其他数据集上表现一般。

David等人\cite{david2015ddos} 提出了一种通过快速熵和基于流量的分析来增强对DDoS攻击的检测的方法。作者将观察到的流量汇总成一个单一的流量，并考虑到每个连接在一定时间间隔内的流量数，而不是取每个连接的数据包数。第二步基本上是计算每个连接的流量计数的快速熵。最后，根据快速熵和流量计数的均值和标准差生成一个自适应阈值。阈值随流量模式状况不断更新，提高了检测精度，同时快速熵的使用减少了计算处理时间。

% Amaral等人[129] 提出了一种基于流量特征的异常检测系统，该系统同时使用IP Flow属性和图表示。该算法基于香农熵的一种泛化类型，Tasallis熵。和香农熵的主要区别在于它有一个参数可以定义 对熵的结果有贡献。通过调整异常检测器的敏感性，使其能够适应不同类型的网络，并检测出更多类型的攻击。

% Bhuyan等人[130]提出的工作带来了一种基于离群值的异常检测方法，使用广义熵和互信息来创建一种能够选择相关的、非冗余的特征子集的特征选择技术。作者认为，由于相互信息降低了一个随机变量的不确定性，而广义熵衡量了数据中的不确定性量，因此他们使检测速度更快，更准确。

% 此外，Berezinski等人[131]为了检测现代僵尸网络恶意软件，引入了一种基于香农熵的网络异常检测器。他们的方法创建了一个网络配置文件，它存储了5分钟滑动时间窗口中的最小和最大熵值。这些值被用于与观察到的熵进行比较。这定义了一个阈值，因此，可以识别不同特征分布的异常分散或集中。最后，作者使用流行的分类器，如决策树和贝叶斯网络，以便对异常进行分类。



\subsubsection{KL散度}
KL散度，又称相对熵，通常用于测量一个随机变量$X$的真实概率分布$P$与任意概率分布$Q$($P$的近似)之间的差异。设 $p(x)$、$q(x)$是离散随机变量 $X$ 中取值的两个概率分布，则 $p$ 对 $q$ 的相对熵是：
\begin{equation}
    D_{KL}(p||q) = \sum_x p(x) \log \frac{p(x)}{q(x)} = E_{p(x)} \log \frac{p(x)}{q(x)}
\end{equation}
在机器学习中，$P$往往用来表示样本的真实分布，$Q$用来表示模型所预测的分布。


Xie等人\cite{xie2016distributed} 利用KL散度着重检测了无线传感器网络(WSN)中的一种特殊类型的异常，这种异常会同时出现在邻近节点的集合中，并持续相当长的时间。基于节点的技术在此场景下效果和效率都不尽如人意。作者提出了基于分布式段的递归核密度估计，通过计算两个时间段的概率密度函数的差异，来判断是否发生了异常。同时也为了以较低的通信成本实现分布式估计，作者采用KL散度作为度量方法。利用真实世界的数据集对算法进行评估，结果表明，该算法可以以更低的通信成本实现很好的性能。

Li等人\cite{li2012differential} 以检测无线传感器网络中的异常数据值为目标，提出了一种基于差分KL散度的异常检测方案。该方案首先将整个传感器网络划分为若干个簇，每个簇中的传感器在物理上相互接近，并且具有相似的感知值。然后，在每个簇内使用KL散度，以通过统计测量两个数据集之间的差异来检测异常值。他们的工作取得了良好的检测率和较低的误报率，同时比其他文献中的类似研究消耗更少的CPU、内存等资源。



% Ambusaidi等人（2014）中提出了一种基于非线性相关系数（NCC）的相似性测量方法，以提取网络流量之间的线性和非线性相关性。提取的相关信息用于检测恶意网络行为。Pearson׳s相关系数是一种基本的线性相关方法，用于找出两个变量之间的依赖关系(Ahmed等，2015c)，然而，在一些数据集中，不同变量之间存在非线性相关，如网络流量中。NCC由Wang等(2005)定义，如式(18)，其中和为变量X和Y的修正熵。

% 给定一组m个正常训练数据实例，首先计算NCC。对于任何传入实例，传入实例与正常实例之间的NCC记录为 。对于用户定义的阈值σ，其范围在0和1之间，如果NCC的差异大于σ，则认为一个传入流量实例是异常的（19）。


% 在Tan等(2014a)中，针对DoS攻击检测，提出了一个利用多元相关分析(MCA)的系统，通过提取网络流量特征之间的几何相关性，来实现网络流量的精确特征分析。检测过程主要包含三个步骤，如图6所示。在步骤1中，在一个明确的时间区间内生成基本特征。第2步包含多元相关分析，应用 "三角区域图生成 "模块，提取第一步得出的每个流量实例中两个不同特征之间的相关性。第三步是基于训练和测试阶段的决策。


% 基于这些知识，可以建立适当的异常检测模型。有监督的异常检测技术需要先有一个训练数据集，再有一个测试数据来评估模型的性能。在这种情况下，首先，使用信息理论措施来确定模型是否适合测试新数据集。Noble和Cook(2003)在基准DARPA和UNM审计数据集上进行了实验，以证明信息理论措施的效用，并得出结论，它们可以用来创建高效的异常检测模型，也可以用来解释它们的性能

% Tan等人(2014a)中的多变量相关分析方法的概念被纳入到网络流量实例的表征中，并将其转换为相应的图像。这些图像被用于DoS攻击检测，基于一个广泛使用的异构度量，即地球移动者距离（Earth Mover׳s Distance，EMD）（Rubner等，1998）。EMD考虑了跨区域匹配，比其他一些著名的异同度测量方法更准确地评估了分布之间的异同度。

\subsection{基于聚类的异常检测算法}

% 聚类分析是把彼此相似的对象分成不同的组别，组内的对象是相似的（相关的），而不同组之间是不同的（不相关的）。如果组内的相似性越大，组间的差别越大，说明聚类的效果越好。因此，聚类技术可以用于离群值检测(Outlier Detection)，识别出与正常组别相距较“远”的值，判定为异常值/离群值\cite{2012Cluster}。聚类算法通常是基于距离/密度发现异常点。其关键步骤在于给每个数据点都分配一个离散度，针对给定的数据集，对其中的任意一个数据点，如果在其局部邻域内的点都很密集，那么认为此数据点为正常数据点，而异常点则是距离正常数据点最近邻的点都比较远的数据点。通常由阈值进行距离远近的界定。


Rajasegar等人\cite{2014Hyperspherical}发明了一种聚类算法，是根据分布式超球面集群得出的，主要作用在于检查测试无线传感器网络中有无异常。
% 提出了一种基于分布式超球面集群的聚类算法，用于检测无线传感器网络中的异常。
该算法利用聚类对每个节点的流量数据进行建模，通过使用k个最近邻（KNN）集群的平均集群间距来识别异常集群，就可以将数据向量分类为正常或异常。该算法的特点是在分布式系统下进行，传感器节点上报集群聚类的信息，在与其他节点通信之前，由中间节点先行合并，从而使得通信开销最小化。


K-means是一种经典的聚类技术，能够将数据分为不同的类别，但是它存在局部收敛性和对聚类中心点选择的敏感性等缺点。因此，许多研究者尝试将k-means与其他技术相结合，以克服这些缺点。Karami等人\cite{2015Karami}设计了一种基于粒子群优化(particle swarm optimization，PSO)和k-means与局部优化混合的模糊异常检测系统，以确定最优的簇数。它分为两个阶段：训练阶段旨在通过将PSO的全局搜索的边界处理方法与k-means的快速收敛相结合，既要找到近似的最优解，也要尽量使局部最优解的困境不要发生。
% 找到近似最优解，同时避免陷入局部最优解的困境。
在检测阶段，由于对于任何数据(正常或攻击)，都有可能与某些集群处于近距离，因此通过引入模糊方法，可以有效降低误报率。



Carvalho等人\cite{carvalho2016unsupervised} 开发了一种主动式网络监控系统，可以检测异常事件，减少决策中的人工干预和错误概率。他们提出一种创建网络基线轮廓DSNSF（使用流量分析的网段数字签名）的方法。该方法通过修改蚁群优化算法，使用聚类方法描述正常的网络使用情况，该方法称为ACODS。ACODS在大量高维输入数据中，通过无监督学习机制优化提取行为模式，对网络流量发现进行表征。然后为了检测异常行为，他们首先计算每个时间区间内真实流量与正常曲线的相似度；然后计算序列之间的距离，并提供基于距离的测量方法。
作者所提出的告警系统采用七种流量属性(Bits， Bytes， Flows， Origin IP， Destination IP， Origin Port， Destination Port)工作，利用熵来计算IP地址和端口特征的相关信息。当检测到异常时，ACODS会提供一份包含IP流量信息的完整报告，说明每个属性对检测到的异常时间间隔的影响。ACODS具有平方复杂度，导致解的收敛要经过多次迭代，作者试图通过使用局部搜索和信息素更新来缓解。

Dromard等人\cite{dromard2016online} 提出了一种基于网格增量聚类算法和离散时间滑动窗口的无监督异常检测器。网格增量聚类比常规的聚类算法更有效率，因为后者只更新之前的特征空间分区，而不是每当增加或删除很少的点时，就对整个空间进行重新分区。增量网格聚类的使用有助于降低系统复杂度，从而使其在实时检测方面更加可行。最后系统合并这些更新的分区，用以识别最不相似的异常值。


Syarif等人\cite{2012syarif} 研究了各种聚类算法在应用于异常检测时的性能。他们使用了五种不同的方法，即k-means、改进的k-means、k-medoids、期望最大化（EM）聚类和基于距离的异常检测算法。表\ref{聚类算法}展示了这些算法在NSL-KDD数据集下的性能表现。

\begin{table}[]
  \caption{聚类算法在NSL-KDD数据集的性能对比}
  \label{聚类算法}
    \centering
    \begin{tabular}{@{}clllclcl@{}}
    \toprule
    \multicolumn{4}{c}{Algorithm}                          & \multicolumn{2}{c}{Accuracy(\%)} & \multicolumn{2}{c}{False positive(\%)} \\ \midrule
    \multicolumn{4}{c}{k-means}                            & \multicolumn{2}{c}{57.81}        & \multicolumn{2}{c}{22.95}              \\
    \multicolumn{4}{c}{Improved k-means}                   & \multicolumn{2}{c}{65.4}         & \multicolumn{2}{c}{21.52}              \\
    \multicolumn{4}{c}{k-medoids}                          & \multicolumn{2}{c}{76.71}        & \multicolumn{2}{c}{21.83}              \\
    \multicolumn{4}{c}{EM clustering}                      & \multicolumn{2}{c}{78.06}        & \multicolumn{2}{c}{20.74}              \\
    \multicolumn{4}{c}{Distance-based   anomaly detection} & \multicolumn{2}{c}{80.15}        & \multicolumn{2}{c}{21.14}              \\ \bottomrule
    \end{tabular}
    \end{table}
% 异常检测方法的一些主要局限性基本上是：没有标签数据；发现新的未知异常模式；噪声数据；高误报率。为了克服这些问题，Bigdeli等人[103]提出了一种基于增量两层集群的异常检测结构。其核心思想是对网络数据进行聚类，并将这些聚类表示为高斯混合物模型，因此该模型可以对新的实例进行分类，也可以检测并忽略冗余的实例。此外，针对误报率较高的问题，采用集体标记的方法，对新入库实例进行集体标记和增量标记。


% 聚类指的是无监督学习算法，它不需要预先标记数据来提取相似数据实例的分组规则（Jain等，1999）。虽然有不同类型的聚类技术，但我们讨论常规聚类和共聚类对网络异常检测的有用性。常规聚类和共聚类的区别在于行和列的处理。常规聚类技术如k-means（Ahmed和Naser，2013）考虑数据集的行进行聚类，而共聚类则同时考虑数据集的行和列来产生聚类（Ahmed等人，2015d）。

% 下面简单讨论一下使用聚类检测异常时总是要做的三个关键假设。
% 假设1：由于我们只能创建正常数据的聚类，因此，后续任何与现有正常数据聚类不相适应的新数据都被认为是异常数据；例如，由于基于密度的聚类算法不包括聚类内的噪声（Ester等人，1996），噪声被认为是异常数据。

% 假设2：当一个簇同时包含正常数据和异常数据时，已经发现正常数据靠近最近的簇中心点，但异常数据远离中心点（Ahmed和Naser，2013）。在这种假设下，异常事件使用距离得分来检测。

% 假设3：在一个具有不同大小的聚类中，较小和较稀疏的聚类可以被认为是异常的，较厚的聚类是正常的。属于大小和/或密度低于阈值的聚类的实例被认为是异常的。


% Münz等人(2007)对异常数据采用的方法非常直接。他们使用k-means聚类来生成正常和异常聚类。一旦实现聚类，就使用以下假设进行分析。

% 如果一个实例比异常簇中心点更接近正常，则该实例被列为正常，反之亦然。


% 如果实例与中心点之间的距离大于预定义的阈值(dmax)，则该实例被视为异常；以及


% 如果一个实例比正常聚类中心点更接近异常聚类中心点，或者它与正常聚类中心点的距离大于预定义的阈值，则被视为异常。


% Petrovic等(2006)提出了一种基于聚类评价技术组合的聚类标签策略。将Davies-Bouldin聚类评价指数和聚类中心直径的比较结合起来，以充分应对攻击向量的特性。他们考虑了相应聚类的紧凑性和它们之间的分离度，以及区分分析网络中 "正常 "和 "异常 "行为的主要参数。然而，他们并没有解释他们的k-means聚类使用k=2的原因。根据他们的方法，攻击向量通常非常相似，如果不是完全相同的话；例如，在大规模攻击的情况下，相应的聚类是非常紧凑的，这种聚类的Davies-Bouldin指数要么是0（当非攻击聚类是空的时候），要么是非常接近0。考虑到攻击向量之间的预期相似性，因为攻击聚类的中心点的直径预期比非攻击聚类的直径小，他们可以区分正常和异常的聚类。

% Portnoy等(2001)提出了基于宽度的聚类来对数据实例进行分类。宽度是恒定的，对所有聚类都保持不变。一旦进行聚类，基于正常实例在整个数据集中占压倒性比例的假设，N\%的聚类是正常的，其余是异常的。利用这一假设，Leung和Leckie（2005）提出了一种基于密度和网格的聚类算法，该算法适用于无监督的异常检测。



% \subsection{基于深度学习的异常检测算法}
% 随着深度学习的兴起，越来越多的学者尝试用深度学习算法来进行异常检测，尤其是针对时间序列数据，深度学习模型往往表现出惊人的效果。
% 常用的深度学习算法为变分编码器、神经网络[6][14]、生成对抗网络、LSTM[17]、RNN[3][4][10][12][13][15]等。以变分自动编码器(Variational Auto-Encoder)[5]为例，其利用自编码器的重构误差和局部误差，针对时间序列的异常检测的场景，达到了很好的效果。

% \section{异常检测领域开源数据集介绍}
% 数据集主要由KDDCUP99， CICIDS等。网络流量异常检测领域最为经典的数据集当属KDD99，但是这个数据集年代过于久远，对于现在的网络环境早已不适用。 NSL-KDD是为了解决KDD'99数据集的一些固有问题而提出的数据集。虽然，这个新版本的KDD数据集仍然存在McHugh所讨论的一些问题，并且可能不能完美地代表现有的真实网络，但由于缺乏基于网络的IDS的公共数据集，我们相信它仍然可以作为一个有效的基准数据集来帮助研究人员比较不同的入侵检测方法。

% 此外，NSL-KDD训练集和测试集的记录数量是合理的。这一优势使得在完整的集合上运行实验是经济实惠的，而不需要随机选择一小部分。因此，不同研究工作的评价结果将具有一致性和可比性。

% % CICIDS2017数据集包含了良性的和最新的常见攻击，与真实的现实世界数据（PCAPs）相似。它还包括使用CICFlowMeter进行网络流量分析的结果，并根据时间戳、源和目的IP、源和目的端口、协议和攻击（CSV文件）对流量进行了标注。同时还提供了提取的特征定义。

% 生成真实的背景流量是我们构建这个数据集的首要任务。我们使用了我们提出的B-Profile系统（Sharafaldin，等人，2016）来对人类交互的抽象行为进行剖析，并生成自然的良性背景流量。对于这个数据集，我们基于HTTP、HTTPS、FTP、SSH和电子邮件协议建立了25个用户的抽象行为。

% 数据采集期从2017年7月3日（周一）上午9点开始，到2017年7月7日（周五）下午5点结束，共5天。其中周一为正常日，只包括良性流量。实施的攻击包括蛮力FTP、蛮力SSH、DoS、Heartbleed、Web攻击、渗透、僵尸网络和DDoS。它们在周二、周三、周四和周五的上午和下午都被执行过。

% % 在我们最近的数据集评估框架中(Gharib等人，2016)，我们确定了建立一个可靠的基准数据集所必需的11个标准。之前的IDS数据集都无法覆盖这11项标准的全部内容。在下文中，我们简要地概述了这些标准。

% THU-IDS 清华校园网数据集，该数据集为真实流量，将于第三章进行介绍。

% https://www.unb.ca/cic/datasets/nsl.html
% \section{异常检测算法对比}
% 对比
% 不同机器学习方法在NSL-KDD数据集上的效果，
\section{现有异常检测算法存在的问题}
截至目前, 异常检测算法的数量已经不可胜数，其中所使用的原理都有差别，针对的领域也各异，流量特征自然也不一样。但通过本文的实验对比我们可以看出，在应对大规模、应用类型多、异常流量是常态且多种异常相互叠加的场景下，现有异常检测算法大多仍存在以下缺陷：

\begin{enumerate}
  \item 面对海量数据规模时，无法或很难做到实时性；
  \item 应用类型多导致的流量特征复杂，因此很难达到较高的检测率和较低的误报率；
  \item 目前的检测算法大多是对异常检测进行二分类，这就导致尽管我们知道数据中存在异常，但是想知道异常的类别以及异常定位，却无法完成。即异常被检测到后，算法无法给出运维人员指导性意见来如何应对。
\end{enumerate}
根据以上几点缺点，想要利用目前已知的异常检测算法精准得判断出异常种类，还是不太现实。确切地说，目前大多数异常检测算法还只停留在证实可行性的阶段。

\section{本章小结}
本章是相关工作综述，首先介绍了网络流量异常的定义和分类，然后按照不同的类别综述了网络流量异常检测的常用算法。最后总结了现有异常检测算法存在的主要问题。

